{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working on https://pyro.ai/examples/bo.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "from torch.distributions import constraints, transform_to\n",
    "\n",
    "import pyro\n",
    "import pyro.contrib.gp as gp\n",
    "\n",
    "assert pyro.__version__.startswith('0.4')\n",
    "pyro.enable_validation(True)  # can help with debugging\n",
    "pyro.set_rng_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const_a = 1.0\n",
    "const_b = 5.1 / (4.0 * math.pow(math.pi, 2))\n",
    "const_c = 5.0 / math.pi\n",
    "const_r = 6.0\n",
    "const_s = 10\n",
    "const_t = 1.0 / (8.0 * math.pi)\n",
    "\n",
    "def branin_hoo_first_term(X):\n",
    "    \n",
    "    fx = const_s * (1.0 - const_t) * torch.cos(X[0]) + const_s\n",
    "    \n",
    "    return fx\n",
    "\n",
    "def branin_hoo(X):\n",
    "    \n",
    "    fx = branin_hoo_first_term(X) + \\\n",
    "        const_a * torch.pow(X[1] - const_b * torch.pow(X[0], 2) + const_c * X[0] - const_r, 2)\n",
    "    \n",
    "    return fx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 1000\n",
    "strides = 200\n",
    "\n",
    "const_x1_min = -5\n",
    "const_x1_max = 10\n",
    "\n",
    "X1 = torch.linspace(const_x1_min, const_x1_max, steps)\n",
    "\n",
    "const_x2_min = 0\n",
    "const_x2_max = 15\n",
    "\n",
    "X2 = torch.linspace(const_x2_min, const_x2_max, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot f(x)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "X1_mesh, X2_mesh = torch.meshgrid(X1, X2)\n",
    "\n",
    "Z_mesh = branin_hoo(torch.stack((X1_mesh, X2_mesh)))\n",
    "\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.contour3D(X1_mesh, X2_mesh, Z_mesh, strides)\n",
    "\n",
    "ax.set_xlabel('x1')\n",
    "ax.set_ylabel('x2')\n",
    "ax.set_zlabel('b-hoo')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# initialize the model with four input points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train = torch.tensor([x for x in np.random.uniform(low=const_x1_min, high=const_x1_max, size=5)])\n",
    "X2_train = torch.tensor([x for x in np.random.uniform(low=const_x2_min, high=const_x2_max, size=5)])\n",
    "\n",
    "X_train = torch.stack((X1_train, X2_train))\n",
    "Y_train = branin_hoo(X_train)\n",
    "\n",
    "train_cnt = len(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpmodel = gp.models.GPRegression(X_train.T, Y_train, \n",
    "                                 gp.kernels.Matern52(input_dim=2), \n",
    "                                 noise=torch.tensor(0.1), \n",
    "                                 jitter=1.0e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing the gpmodel with the objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_tmp = torch.tensor([-4.9, 4.2, 7.0])\n",
    "X2_tmp = torch.tensor([0.0, -0.8, 7.0])\n",
    "X_tmp = torch.stack((X1_tmp, X2_tmp))\n",
    "\n",
    "f_loc, f_cov = gpmodel(X_tmp.T, full_cov=True)\n",
    "print(\"GP:\", f_loc)\n",
    "\n",
    "bh_temp = branin_hoo(X_tmp)\n",
    "print(\"BH:\", bh_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking LMs\n",
    "print(branin_hoo(\n",
    "        torch.stack((\n",
    "            torch.tensor([-math.pi, math.pi, 9.42478]), \n",
    "            torch.tensor([12.275, 2.275, 2.475])))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_points(bo_ax, gpmodel_, train_cnt):\n",
    "    \n",
    "    # Plotting training data\n",
    "    bo_ax.scatter(\n",
    "        gpmodel_.X.numpy().T[0][:train_cnt], \n",
    "        gpmodel_.X.numpy().T[1][:train_cnt],\n",
    "        marker=\"x\", s=500, c='black')\n",
    "\n",
    "    # Plotting BO steps\n",
    "    bo_ax.scatter(\n",
    "        gpmodel_.X.numpy().T[0][train_cnt:], \n",
    "        gpmodel_.X.numpy().T[1][train_cnt:],\n",
    "        marker=\"o\", s=100, c='red')\n",
    "\n",
    "    for i, iter in enumerate(gpmodel_.X.numpy()):\n",
    "        if i >= train_cnt:\n",
    "            bo_ax.annotate(\"%d\" % (i+1-train_cnt), \n",
    "                        (iter.T[0] + 0.1, iter.T[1] + 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constracting BO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_posterior(x_new):\n",
    "        \n",
    "    bh_y = branin_hoo(x_new.T) # evaluate f at new point.\n",
    "        \n",
    "    X = torch.cat([gpmodel.X, x_new]) # incorporate new evaluation\n",
    "    y = torch.cat([gpmodel.y, bh_y])\n",
    "    \n",
    "    gpmodel.set_data(X, y)\n",
    "    \n",
    "    # optimize the GP hyperparameters using Adam with lr=0.001\n",
    "    optimizer = torch.optim.Adam(gpmodel.parameters(), lr=0.001)\n",
    "    \n",
    "    gp.util.train(gpmodel, optimizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acquisition_function(x):\n",
    "    \n",
    "    return lower_confidence_bound(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_confidence_bound(x, kappa=2):\n",
    "    \n",
    "    mu, variance = gpmodel(x, full_cov=False, noiseless=False)\n",
    "    \n",
    "    sigma = variance.sqrt()\n",
    "    \n",
    "    return mu - kappa * sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_a_candidate(x_init):\n",
    "    \n",
    "    # transform x to an unconstrained domain\n",
    "    constraint_x1 = constraints.interval(const_x1_min, const_x1_max)\n",
    "    constraint_x2 = constraints.interval(const_x2_min, const_x2_max)\n",
    "\n",
    "    unconstrained_x1_init = transform_to(constraint_x1).inv(x_init[:, 0])\n",
    "    unconstrained_x2_init = transform_to(constraint_x2).inv(x_init[:, 1])\n",
    "\n",
    "    unconstrained_x_init = torch.stack((unconstrained_x1_init, unconstrained_x2_init), dim=1)\n",
    "        \n",
    "    unconstrained_x = unconstrained_x_init.clone().detach().requires_grad_(True)\n",
    "    \n",
    "    minimizer = optim.LBFGS([unconstrained_x])\n",
    "\n",
    "    def closure():\n",
    "        minimizer.zero_grad()\n",
    "                \n",
    "        x1_tmp = transform_to(constraint_x1)(unconstrained_x[:, 0])\n",
    "        x2_tmp = transform_to(constraint_x2)(unconstrained_x[:, 1])\n",
    "        \n",
    "        y = lower_confidence_bound(torch.stack((x1_tmp, x2_tmp), dim=1))\n",
    "        \n",
    "        autograd.backward(unconstrained_x, autograd.grad(y, unconstrained_x))\n",
    "                \n",
    "        return y\n",
    "\n",
    "    minimizer.step(closure)\n",
    "   \n",
    "    # after finding a candidate in the unconstrained domain,\n",
    "    # convert it back to original domain.\n",
    "    x1_tmp = transform_to(constraint_x1)(unconstrained_x[:, 0])\n",
    "    x2_tmp = transform_to(constraint_x2)(unconstrained_x[:, 1])\n",
    "    \n",
    "    x = torch.stack((x1_tmp, x2_tmp), dim=1)\n",
    "    \n",
    "    return x.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_x(num_candidates=5):\n",
    "    \n",
    "    candidates = []\n",
    "    values = []\n",
    "\n",
    "    x_init = gpmodel.X[-1:]\n",
    "    \n",
    "    for i in range(num_candidates):\n",
    "                \n",
    "        x = find_a_candidate(x_init)\n",
    "        \n",
    "        y = acquisition_function(x)\n",
    "        \n",
    "        candidates.append(x)\n",
    "        \n",
    "        values.append(y)\n",
    "        \n",
    "        x_init = torch.stack(\n",
    "                (x[:,0].new_empty(1).uniform_(const_x1_min, const_x1_max),\n",
    "                 x[:,1].new_empty(1).uniform_(const_x2_min, const_x2_max)), dim=1)\n",
    "        \n",
    "    argmin = torch.min(torch.cat(values), dim=0)[1].item()\n",
    "    \n",
    "    return candidates[argmin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bo_total_steps = 10\n",
    "no_cols = 3\n",
    "\n",
    "fbo, fbo_axes = plt.subplots(ncols=no_cols, nrows=bo_total_steps, figsize=(no_cols*6, bo_total_steps*6))\n",
    "\n",
    "optimizer = torch.optim.Adam(gpmodel.parameters(), lr=0.001)\n",
    "gp.util.train(gpmodel, optimizer)\n",
    "\n",
    "for i in range(bo_total_steps):\n",
    "\n",
    "    xmin = next_x()\n",
    "    \n",
    "    ########### Ploting prior\n",
    "    Predict_mesh, _ = gpmodel(torch.stack((X1_mesh.flatten(), X2_mesh.flatten())).T) \n",
    "\n",
    "    Predict_mesh = Predict_mesh.reshape((steps, steps)).detach()\n",
    "    fbo_axes[i, 0].contour(X1_mesh, X2_mesh, Predict_mesh, strides)\n",
    "    fbo_axes[i, 0].title.set_text('Step %d: prior' % (i+1))\n",
    "    \n",
    "    ########### Plotting acquisition function\n",
    "    acquisition_mesh = acquisition_function(\n",
    "            torch.stack((X1_mesh.flatten(), X2_mesh.flatten())).T)\n",
    "    \n",
    "    acquisition_mesh = acquisition_mesh.reshape((steps, steps)).detach()\n",
    "    fbo_axes[i, 1].contour(X1_mesh, X2_mesh, acquisition_mesh, strides)\n",
    "    \n",
    "    # Updating posterior\n",
    "    update_posterior(xmin)\n",
    "            \n",
    "    ########### Plotting GP countour plot\n",
    "    Predict_mesh, _ = gpmodel(torch.stack((X1_mesh.flatten(), X2_mesh.flatten())).T) \n",
    "\n",
    "    Predict_mesh = Predict_mesh.reshape((steps, steps)).detach()\n",
    "    fbo_axes[i, 2].contour(X1_mesh, X2_mesh, Predict_mesh, strides)\n",
    "    fbo_axes[i, 2].title.set_text('Step %d: posterior' % (i+1))\n",
    "    \n",
    "    fbo_axes[i, 1].scatter(\n",
    "        gpmodel.X.numpy().T[0][len(gpmodel.X.numpy())-1], \n",
    "        gpmodel.X.numpy().T[1][len(gpmodel.X.numpy())-1],\n",
    "        marker=\"o\", s=100, c='red')\n",
    "    \n",
    "    fbo_axes[i, 1].title.set_text('Step %d: acquisition function' % (i+1))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting BO steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18, 18))\n",
    "CS = ax.contour(X1_mesh, X2_mesh, Z_mesh, levels=200)\n",
    "\n",
    "add_points(ax, gpmodel, train_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18, 9), ncols=2, nrows=1)\n",
    "ax[0].contour(X1_mesh, X2_mesh, Z_mesh, strides)\n",
    "ax[0].title.set_text('Branin-Hoo')\n",
    "\n",
    "ax[1].contour(X1_mesh, X2_mesh, Predict_mesh, strides)\n",
    "ax[1].title.set_text('GP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
